{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.1+cu121\n",
      "2.2.1+cu121\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "os.environ['TORCH'] = torch.__version__\n",
    "print(torch.__version__)\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"./interactive_tutorials\")\n",
    "\n",
    "import pandas as pd\n",
    "# from arango import ArangoClient\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import requests\n",
    "import sys\n",
    "import oasis\n",
    "from arango import ArangoClient\n",
    "from pyArango.connection import Connection\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear\n",
    "from arango import ArangoClient\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import SAGEConv, to_hetero\n",
    "from torch_geometric.transforms import RandomLinkSplit, ToUndirected\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from torch_geometric.data import HeteroData\n",
    "import yaml\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We load in our reviews. This csv was generated thru categorizer.ipynb - the categories are llama3 predicted based on review title + text.\n",
    "Currently, organized_reviews is a small sample (6100/~580000) of rows from the source. There seems to be some internal sorting based on category (e.g. first 5 items are all food) which may bias. \n",
    "TODO: Change to random sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>Pet</td>\n",
       "      <td>Food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>Food</td>\n",
       "      <td>Snack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>Candy</td>\n",
       "      <td>Treat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>Food</td>\n",
       "      <td>Beverage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>Food</td>\n",
       "      <td>Candy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \\\n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...   \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...   \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...   \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...   \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...   \n",
       "\n",
       "  category subcategory  \n",
       "0      Pet        Food  \n",
       "1     Food       Snack  \n",
       "2    Candy       Treat  \n",
       "3     Food    Beverage  \n",
       "4     Food       Candy  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO implement weighting for helpfulness_score\n",
    "metadata_path = './amazon_data_source/organized_reviews.csv'\n",
    "df = pd.read_csv(metadata_path)\n",
    "\n",
    "df.head()\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  941  unique products\n",
      "And reviews from 5844 unique users\n",
      "The average review score is 4.17672131147541\n"
     ]
    }
   ],
   "source": [
    "df.columns\n",
    "print(\"There are \",df['ProductId'].nunique(),\" unique products\")\n",
    "print(\"And reviews from\",df['UserId'].nunique(), \"unique users\")\n",
    "print(\"The average review score is\", df['Score'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 941 unique "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ProductId'] = df['ProductId'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>username</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_title</th>\n",
       "      <th>review_content</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6095</th>\n",
       "      <td>B009HINRX8</td>\n",
       "      <td>ADDBLG0CFY9AI</td>\n",
       "      <td>S.A.D.</td>\n",
       "      <td>5</td>\n",
       "      <td>Best of the Tassimo's</td>\n",
       "      <td>We've tried many Tassimo flavors.  This is by ...</td>\n",
       "      <td>Home</td>\n",
       "      <td>Goods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6096</th>\n",
       "      <td>B009HINRX8</td>\n",
       "      <td>ATNQNZEHWMR9U</td>\n",
       "      <td>Kokopelli</td>\n",
       "      <td>3</td>\n",
       "      <td>Note: Rating both coffee and seller</td>\n",
       "      <td>This coffee is good but, for me, it's nothing ...</td>\n",
       "      <td>Food</td>\n",
       "      <td>Beverage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6097</th>\n",
       "      <td>B009HINRX8</td>\n",
       "      <td>A2CAZG1CQ8BQI5</td>\n",
       "      <td>Patricia J. Nohalty</td>\n",
       "      <td>5</td>\n",
       "      <td>Kona for Tassimo</td>\n",
       "      <td>Of all the coffee's available for Tassimo this...</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Homebrewed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6098</th>\n",
       "      <td>B009UOFU20</td>\n",
       "      <td>AJVB004EB0MVK</td>\n",
       "      <td>D. Christofferson</td>\n",
       "      <td>1</td>\n",
       "      <td>weak coffee not good for a premium product and...</td>\n",
       "      <td>This coffee supposedly is premium, it tastes w...</td>\n",
       "      <td>Home</td>\n",
       "      <td>Supplies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6099</th>\n",
       "      <td>B009WSNWC4</td>\n",
       "      <td>AMP7K1O84DH1T</td>\n",
       "      <td>ESTY</td>\n",
       "      <td>5</td>\n",
       "      <td>DELICIOUS</td>\n",
       "      <td>Purchased this product at a local store in NY ...</td>\n",
       "      <td>Food</td>\n",
       "      <td>Snack</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      product_id         user_id             username  rating  \\\n",
       "6095  B009HINRX8   ADDBLG0CFY9AI               S.A.D.       5   \n",
       "6096  B009HINRX8   ATNQNZEHWMR9U            Kokopelli       3   \n",
       "6097  B009HINRX8  A2CAZG1CQ8BQI5  Patricia J. Nohalty       5   \n",
       "6098  B009UOFU20   AJVB004EB0MVK    D. Christofferson       1   \n",
       "6099  B009WSNWC4   AMP7K1O84DH1T                 ESTY       5   \n",
       "\n",
       "                                           review_title  \\\n",
       "6095                              Best of the Tassimo's   \n",
       "6096                Note: Rating both coffee and seller   \n",
       "6097                                   Kona for Tassimo   \n",
       "6098  weak coffee not good for a premium product and...   \n",
       "6099                                          DELICIOUS   \n",
       "\n",
       "                                         review_content      category  \\\n",
       "6095  We've tried many Tassimo flavors.  This is by ...          Home   \n",
       "6096  This coffee is good but, for me, it's nothing ...          Food   \n",
       "6097  Of all the coffee's available for Tassimo this...   Electronics   \n",
       "6098  This coffee supposedly is premium, it tastes w...          Home   \n",
       "6099  Purchased this product at a local store in NY ...          Food   \n",
       "\n",
       "      subcategory  \n",
       "6095        Goods  \n",
       "6096     Beverage  \n",
       "6097   Homebrewed  \n",
       "6098     Supplies  \n",
       "6099        Snack  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df = df[['ProductId', 'UserId', 'ProfileName', 'Score', 'Summary', 'Text', 'category', 'subcategory']]\n",
    "reviews_df.columns = ['product_id', 'user_id', 'username', 'rating', 'review_title', 'review_content', 'category', 'subcategory']\n",
    "reviews_df = reviews_df.sort_values('product_id')\n",
    "reviews_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "reviews_df['username'] = reviews_df['username'].fillna('unknown')\n",
    "reviews_df['review_title'] = reviews_df['review_title'].fillna('')\n",
    "reviews_df['rating'] = reviews_df['rating'].astype(int) \n",
    "reviews_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#indexes by product_id\n",
    "indices = pd.Series(reviews_df.index, index=reviews_df['product_id']).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product_id        object\n",
      "user_id           object\n",
      "username          object\n",
      "rating             int32\n",
      "review_title      object\n",
      "review_content    object\n",
      "category          object\n",
      "subcategory       object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(reviews_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_mappings(df, index_col):\n",
    "    mapping = {index: i for i, index in enumerate(df[index_col].unique())}\n",
    "    return mapping\n",
    "\n",
    "def create_reverse_mapping(mapping):\n",
    "    return {emb_id: user_id for user_id, emb_id in mapping.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_mapping = node_mappings(reviews_df, index_col='user_id')\n",
    "rev_user_mapping = create_reverse_mapping(user_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_mapping = node_mappings(reviews_df, index_col='product_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B00002NCJC 0\n",
      "B00002Z754 1\n",
      "B000084DVR 2\n",
      "B000084E1U 3\n",
      "B0000CERHH 4\n",
      "B0000CGFV4 5\n",
      "B0000D94SZ 6\n",
      "B0000DC5IY 7\n",
      "B0000E65W9 8\n",
      "B0000GGI00 9\n",
      "B0000TU8EO 10\n",
      "B0000VLH8S 11\n",
      "B0000VMBDI 12\n",
      "B0001217OA 13\n",
      "B00015BQB6 14\n",
      "B00016UX0K 15\n",
      "B0001E3LBU 16\n",
      "B0001FQVCK 17\n",
      "B0001KL1Y8 18\n",
      "B0001N4886 19\n",
      "A13RRPGE79XFFH 0\n",
      "A196AJHU9EASJN 1\n",
      "A29Z5PI9BW2PU3 2\n",
      "A3B8RCEI0FXFI6 3\n",
      "A3DKGXWUEP1AI2 4\n",
      "A1UGDJP1ZJWVPF 5\n",
      "A3DH85EYHW4AQH 6\n",
      "A126F7OK2T4JUX 7\n",
      "A29VLI9PBSO927 8\n",
      "AOJ6IGSCY7SO9 9\n",
      "A3LSUKN4IFS6VD 10\n",
      "A2R91PG1XPNO0B 11\n",
      "A3GKE33FI1QKA 12\n",
      "AGYZZ3QXV9S8 13\n",
      "A1GJ37VZOZ6S1W 14\n",
      "A1GYEGLX3P2Y7P 15\n",
      "A23EN4MZKDZIDV 16\n",
      "A2VBTN6ZR67YOF 17\n",
      "A2D16Q29G5S0E9 18\n",
      "A21EHWHI9XQY10 19\n"
     ]
    }
   ],
   "source": [
    "from itertools import islice\n",
    "\n",
    "\n",
    "for key, value in islice(product_mapping.items(), 20):\n",
    "    print(key, value)\n",
    "for key, value in islice(user_mapping.items(), 20):\n",
    "    print(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "941"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_id = reviews_df['product_id'].tolist()\n",
    "p_id = list(dict.fromkeys(p_id))\n",
    "len(p_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##ArangoDB setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting new temp credentials.\n",
      "Temp database ready to use.\n"
     ]
    }
   ],
   "source": [
    "# get temporary credentials for ArangoDB on cloud\n",
    "login = oasis.getTempCredentials(tutorialName=\"MovieRecommendations\", credentialProvider=\"https://tutorials.arangodb.cloud:8529/_db/_system/tutorialDB/tutorialDB\")\n",
    "\n",
    "# Connect to the temp database\n",
    "# Please note that we use the python-arango driver as it has better support for ArangoSearch\n",
    "product_rec_db = oasis.connect_python_arango(login)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://tutorials.arangodb.cloud:8529\n",
      "Username: TUTi7laedtbc3qew20zgtf2vo\n",
      "Password: TUTeh99uje2o88ue51axbd1tk\n",
      "Database: TUTzveg5qo7hudznlw1jok7x\n"
     ]
    }
   ],
   "source": [
    "# url to access the ArangoDB Web UI\n",
    "print(\"https://\"+login[\"hostname\"]+\":\"+str(login[\"port\"]))\n",
    "print(\"Username: \" + login[\"username\"])\n",
    "print(\"Password: \" + login[\"password\"])\n",
    "print(\"Database: \" + login[\"dbName\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not product_rec_db.has_collection(\"Product\"):\n",
    "    product_rec_db.create_collection(\"Product\", replication_factor=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = []\n",
    "BATCH_SIZE = 128\n",
    "batch_idx = 1\n",
    "index = 0\n",
    "product_collection = product_rec_db[\"Product\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 941/941 [00:00<00:00, 2280.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting batch the last batch!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for idx in tqdm(range(len(p_id))):\n",
    "    insert_doc = {}\n",
    "    product_id = str(p_id[idx])\n",
    "\n",
    "    emb_id = \"Product/\" + str(product_mapping[p_id[idx]])\n",
    "    insert_doc[\"_id\"] = emb_id\n",
    "    \n",
    "    insert_doc[\"productId\"] = p_id[idx]\n",
    "\n",
    "    batch.append(insert_doc)\n",
    "    index +=1\n",
    "    last_record = (idx == (len(p_id) - 1))\n",
    "    if index % BATCH_SIZE == 0:\n",
    "        #print(\"Inserting batch %d\" % (batch_idx))\n",
    "        batch_idx += 1\n",
    "        product_collection.import_bulk(batch)\n",
    "        batch = []\n",
    "    if last_record and len(batch) > 0:\n",
    "        print(\"Inserting batch the last batch!\")\n",
    "        product_collection.import_bulk(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Creating User Collection\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not product_rec_db.has_collection(\"Users\"):\n",
    "    product_rec_db.create_collection(\"Users\", replication_factor=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of Users: 5844\n"
     ]
    }
   ],
   "source": [
    "total_users = np.unique(reviews_df[['user_id']].values.flatten()).shape[0]\n",
    "print(\"Total number of Users:\", total_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uploads all users to ArangoDB\n",
    "def populate_user_collection(total_users):\n",
    "    batch = []\n",
    "    BATCH_SIZE = 50\n",
    "    batch_idx = 1\n",
    "    index = 0\n",
    "    user_ids = list(user_mapping.keys())\n",
    "    user_collection = product_rec_db[\"Users\"]\n",
    "    for idx in tqdm(range(total_users)):\n",
    "        insert_doc = {}\n",
    "\n",
    "        insert_doc[\"_id\"] = \"Users/\" + str(user_mapping[user_ids[idx]])\n",
    "        insert_doc[\"original_id\"] = str(user_ids[idx])\n",
    "\n",
    "        batch.append(insert_doc)\n",
    "        index +=1\n",
    "        last_record = (idx == (total_users - 1))\n",
    "        if index % BATCH_SIZE == 0:\n",
    "            #print(\"Inserting batch %d\" % (batch_idx))\n",
    "            batch_idx += 1\n",
    "            user_collection.import_bulk(batch)\n",
    "            batch = []\n",
    "        if last_record and len(batch) > 0:\n",
    "            print(\"Inserting batch the last batch!\")\n",
    "            user_collection.import_bulk(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5844/5844 [00:05<00:00, 1022.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting batch the last batch!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "populate_user_collection(total_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Ratings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Ratings collection in ArangoDB\n",
    "if not product_rec_db.has_collection(\"Ratings\"):\n",
    "    product_rec_db.create_collection(\"Ratings\", edge=True, replication_factor=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining graph schema in ArangoDB\n",
    "\n",
    "# create a new graph called product_rating_graph in the temp database if it does not already exist.\n",
    "if not product_rec_db.has_graph(\"product_rating_graph\"):\n",
    "    product_rec_db.create_graph('product_rating_graph')\n",
    "\n",
    "# This returns and API wrapper for the above created graphs -> so we can command straight to the graph\n",
    "product_rating_graph = product_rec_db.graph(\"product_rating_graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating\n"
     ]
    }
   ],
   "source": [
    "if not product_rating_graph.has_vertex_collection(\"Users\"):\n",
    "    print(\"creating\")\n",
    "    product_rating_graph.vertex_collection(\"Users\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating\n"
     ]
    }
   ],
   "source": [
    "if not product_rating_graph.has_vertex_collection(\"Product\"):\n",
    "    print(\"creating\")\n",
    "    product_rating_graph.vertex_collection(\"Product\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating edge definitions named \"Ratings. This creates any missing\n",
    "# collections and returns an API wrapper for \"Ratings\" edge collection.\n",
    "if not product_rating_graph.has_edge_definition(\"Ratings\"):\n",
    "    Ratings = product_rating_graph.create_edge_definition(\n",
    "        edge_collection='Ratings',\n",
    "        from_vertex_collections=['Users'],\n",
    "        to_vertex_collections=['Product']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A13RRPGE79XFFH' 'A196AJHU9EASJN' 'A29Z5PI9BW2PU3' 'A3B8RCEI0FXFI6'\n",
      " 'A3DKGXWUEP1AI2'] (6100,) [5 4 5 5 5]\n"
     ]
    }
   ],
   "source": [
    "user_id, product_id, ratings = reviews_df[['user_id']].values.flatten(), reviews_df[['product_id']].values.flatten() , reviews_df[['rating']].values.flatten()\n",
    "\n",
    "print(user_id[:5], product_id.shape, ratings[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ratings_graph(user_id, product_id, ratings):\n",
    "    batch = []\n",
    "    BATCH_SIZE = 100\n",
    "    batch_idx = 1\n",
    "    index = 0\n",
    "    edge_collection = product_rec_db[\"Ratings\"]\n",
    "    for idx in tqdm(range(ratings.shape[0])):\n",
    "        insert_doc = {}\n",
    "        insert_doc = {\n",
    "                        \"_from\":  (\"Users\" + \"/\" + str(user_mapping[user_id[idx]])),\n",
    "                        \"_to\":    (\"Product\" + \"/\" + str(product_mapping[product_id[idx]])),\n",
    "                        \"_rating\": float(ratings[idx])}\n",
    "\n",
    "        batch.append(insert_doc)\n",
    "        index += 1\n",
    "        last_record = (idx == (ratings.shape[0] - 1))\n",
    "\n",
    "        if index % BATCH_SIZE == 0:\n",
    "            #print(\"Inserting batch %d\" % (batch_idx))\n",
    "            batch_idx += 1\n",
    "            edge_collection.import_bulk(batch)\n",
    "            batch = []\n",
    "        if last_record and len(batch) > 0:\n",
    "            print(\"Inserting batch the last batch!\")\n",
    "            edge_collection.import_bulk(batch)    \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6100/6100 [00:03<00:00, 1931.50it/s]\n"
     ]
    }
   ],
   "source": [
    "create_ratings_graph(user_id, product_id, ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch O'Clock!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = product_rec_db.collection('Users')\n",
    "products = product_rec_db.collection('Product')\n",
    "ratings_graph = product_rec_db.collection('Ratings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5844, 941, 6100)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(users), len(products), len(ratings_graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pyg_edges(rating_docs):\n",
    "    src = []\n",
    "    dst = []\n",
    "    ratings = []\n",
    "    for doc in rating_docs:\n",
    "        _from = int(doc['_from'].split('/')[1])\n",
    "        _to   = int(doc['_to'].split('/')[1])\n",
    "\n",
    "        src.append(_from)\n",
    "        dst.append(_to)\n",
    "        ratings.append(int(doc['_rating']))\n",
    "\n",
    "    edge_index = torch.tensor([src, dst])\n",
    "    edge_label = torch.tensor(ratings)\n",
    "\n",
    "    return edge_index, edge_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index, edge_label = create_pyg_edges(product_rec_db.aql.execute('FOR doc IN Ratings RETURN doc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 6100])\n",
      "torch.Size([6100])\n"
     ]
    }
   ],
   "source": [
    "print(edge_index.shape)\n",
    "print(edge_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product_id\n",
      "B00002NCJC                      [Flies Begone, thirty bucks?]\n",
      "B00002Z754    [Great Product, WOW Make your own 'slickers' !]\n",
      "B000084DVR         [Premium Quality Dog Food!!!, Good stuff!]\n",
      "B000084E1U                                    [Cats love it!]\n",
      "B0000CERHH              [Delicious Tea, Love this tea!, WOW!]\n",
      "Name: review_title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "product_reviews = reviews_df.groupby('product_id')['review_title'].apply(list)\n",
    "print(product_reviews.head())\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english') \n",
    "tfidf_matrix = vectorizer.fit_transform(product_reviews.apply(' '.join)) # Fit transform on combined reviews\n",
    "# Clustering \n",
    "num_clusters = 10\n",
    "kmeans = KMeans(n_clusters=num_clusters)\n",
    "kmeans.fit(tfidf_matrix)\n",
    "\n",
    "\n",
    "def cluster_product_reviews(product_reviews):\n",
    "    review_text = ' '.join(product_reviews)  # Combine reviews into a single text\n",
    "    tfidf_vector = vectorizer.transform([review_text])\n",
    "    cluster_label = kmeans.predict(tfidf_vector)[0]\n",
    "    return cluster_label\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "941\n",
      "941\n",
      "    product_id  cluster                                            reviews\n",
      "0   B00002NCJC        0                      [Flies Begone, thirty bucks?]\n",
      "1   B00002Z754        9    [Great Product, WOW Make your own 'slickers' !]\n",
      "2   B000084DVR        5         [Premium Quality Dog Food!!!, Good stuff!]\n",
      "3   B000084E1U        5                                    [Cats love it!]\n",
      "4   B0000CERHH        6              [Delicious Tea, Love this tea!, WOW!]\n",
      "5   B0000CGFV4        0             [Nice, Big Pieces & Big Almond Flavor]\n",
      "6   B0000D94SZ        1              [A Summer Treat Fat Free, Guilt Free]\n",
      "7   B0000DC5IY        9  [Little Flavor, Don't buy this product unless ...\n",
      "8   B0000E65W9        0  [A Staple in my house, A favorite quick meal s...\n",
      "9   B0000GGI00        2  [This is the stuff!, What everyone is saying h...\n",
      "10  B0000TU8EO        0                                             [YUM.]\n",
      "11  B0000VLH8S        0  [The Inexpensive Alternative to Gold Leaf!, no...\n",
      "12  B0000VMBDI        1  [Cake Topper, Wilton 13 pc golf set, Really cu...\n",
      "13  B0001217OA        0                                        [Fantastic]\n",
      "14  B00015BQB6        3                 [beans, yummy, Adzuki beans, Yum.]\n",
      "15  B00016UX0K        2  [I'm with the crowd. Best all purpose sauce ev...\n",
      "16  B0001E3LBU        0                                     [Great Jerky!]\n",
      "17  B0001FQVCK        0  [Chocolate Italian kisses - need I say more?, ...\n",
      "18  B0001KL1Y8        0                                      [A great buy]\n",
      "19  B0001N4886        6               [Wonderful tea!!, Smooth Rich Blend]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(len(product_reviews))\n",
    "cluster_labels = kmeans.labels_\n",
    "print(len(cluster_labels))\n",
    "\n",
    "cluster_data = pd.DataFrame({\n",
    "    'product_id': product_reviews.index,  # Get the product IDs\n",
    "    'cluster': cluster_labels,\n",
    "    'reviews': product_reviews.values\n",
    "})\n",
    "print(cluster_data.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CategoryEncoder(product_docs , model_name=None):\n",
    "    product_category = list(product_docs['category'])\n",
    "    print(\"sample categories are\", product_category[:5])\n",
    "    product_subcategory = list(product_docs['subcategory'])\n",
    "    product_concategories = [cat + subcat for cat, subcat in zip(product_category, product_subcategory)]\n",
    "    print(\"sample concat: \", product_concategories[:5])\n",
    "    model = SentenceTransformer(model_name, device=device)\n",
    "    product_category_embeddings = model.encode(product_concategories, show_progress_bar=True,\n",
    "                              convert_to_tensor=True, device=device)\n",
    "    print(\"Shape of product_id_embeddings before returning:\", product_category_embeddings.shape)\n",
    "\n",
    "    return product_category_embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "def ClustersEncoder(product_docs, cluster_labels): \n",
    "    \n",
    "    num_clusters = len(set(cluster_labels))   \n",
    "    x = torch.zeros(len(product_docs), num_clusters) \n",
    "\n",
    "    for i, doc in enumerate(product_docs):  \n",
    "        cluster_label = cluster_labels[i]  # Get the corresponding label\n",
    "        x[i, cluster_label] = 1 # One-hot encoding for the cluster label\n",
    "\n",
    "    return x.to(device) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.]], device='cuda:0')\n",
      "There are 941 products across 10 categories: torch.Size([941, 10])\n"
     ]
    }
   ],
   "source": [
    "#TODO plotly express to view clusters \n",
    "#reviews_df['cluster'] = reviews_df['cluster'].fillna(-1).astype(int) # Fill NaNs with -1 and convert to int\n",
    "#cluster_assignments = reviews_df['cluster'] \n",
    "cluster_emb = ClustersEncoder(products, cluster_labels) \n",
    "print(cluster_emb)\n",
    "print(\"There are 941 products across 10 categories:\", cluster_emb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_embeddings(category_emb, cluster_emb):\n",
    "    assert category_emb.shape[0] == cluster_emb.shape[0], \"Number of samples in both embeddings must match.\" \n",
    "    return torch.cat((category_emb, cluster_emb), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      product_id         user_id                     username  rating  \\\n",
      "0     B00002NCJC  A13RRPGE79XFFH                     reader48       5   \n",
      "1     B00002NCJC  A196AJHU9EASJN                 Alex Chaffee       4   \n",
      "2     B00002Z754  A29Z5PI9BW2PU3                       Robbie       5   \n",
      "3     B00002Z754  A3B8RCEI0FXFI6                    B G Chase       5   \n",
      "4     B000084DVR  A3DKGXWUEP1AI2  Glenna E. Bauer \"Puppy Mum\"       5   \n",
      "...          ...             ...                          ...     ...   \n",
      "6095  B009HINRX8   ADDBLG0CFY9AI                       S.A.D.       5   \n",
      "6096  B009HINRX8   ATNQNZEHWMR9U                    Kokopelli       3   \n",
      "6097  B009HINRX8  A2CAZG1CQ8BQI5          Patricia J. Nohalty       5   \n",
      "6098  B009UOFU20   AJVB004EB0MVK            D. Christofferson       1   \n",
      "6099  B009WSNWC4   AMP7K1O84DH1T                         ESTY       5   \n",
      "\n",
      "                                           review_title  \\\n",
      "0                                          Flies Begone   \n",
      "1                                         thirty bucks?   \n",
      "2                                         Great Product   \n",
      "3                        WOW Make your own 'slickers' !   \n",
      "4                           Premium Quality Dog Food!!!   \n",
      "...                                                 ...   \n",
      "6095                              Best of the Tassimo's   \n",
      "6096                Note: Rating both coffee and seller   \n",
      "6097                                   Kona for Tassimo   \n",
      "6098  weak coffee not good for a premium product and...   \n",
      "6099                                          DELICIOUS   \n",
      "\n",
      "                                         review_content      category  \\\n",
      "0     We have used the Victor fly bait for 3 seasons...           Pet   \n",
      "1     Why is this $[...] when the same product is av...          Home   \n",
      "2     This was a really good idea and the final prod...        Crafts   \n",
      "3     I just received my shipment and could hardly w...        Office   \n",
      "4     We have been using this food for about 6 month...           Pet   \n",
      "...                                                 ...           ...   \n",
      "6095  We've tried many Tassimo flavors.  This is by ...          Home   \n",
      "6096  This coffee is good but, for me, it's nothing ...          Food   \n",
      "6097  Of all the coffee's available for Tassimo this...   Electronics   \n",
      "6098  This coffee supposedly is premium, it tastes w...          Home   \n",
      "6099  Purchased this product at a local store in NY ...          Food   \n",
      "\n",
      "      subcategory  \n",
      "0          Supply  \n",
      "1            Pest  \n",
      "2          Decals  \n",
      "3        Supplies  \n",
      "4            Food  \n",
      "...           ...  \n",
      "6095        Goods  \n",
      "6096     Beverage  \n",
      "6097   Homebrewed  \n",
      "6098     Supplies  \n",
      "6099        Snack  \n",
      "\n",
      "[6100 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "print(reviews_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster embeddings shape is:  torch.Size([941, 10]) \n",
      "\n",
      "sample categories are [' Pet', ' Crafts', ' Pet', ' Pet', ' Home']\n",
      "sample concat:  [' Pet Supply', ' Crafts Decals', ' Pet Food', ' Pet Food', ' Home Goods']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aac5458610c94ec5adcd9deccf73ce92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of product_id_embeddings before returning: torch.Size([941, 384])\n",
      "Category Embeddings shape: torch.Size([941, 384])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import nbformat\n",
    "from sklearn.manifold import TSNE\n",
    "#goes through database and  passes products into encoder, which gives us product embeddings\n",
    "unique_products_df = reviews_df.drop_duplicates('product_id')\n",
    "cluster_emb = ClustersEncoder(products, cluster_labels) \n",
    "print(\"cluster embeddings shape is: \", cluster_emb.shape, \"\\n\")\n",
    "category_emb = CategoryEncoder(unique_products_df, model_name='all-MiniLM-L6-v2')\n",
    "print('Category Embeddings shape:', category_emb.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([941, 394])\n"
     ]
    }
   ],
   "source": [
    "concat_emb = concatenate_embeddings(category_emb, cluster_emb)\n",
    "print(concat_emb.shape)\n",
    "torch.save(concat_emb, \"concatenated_embeddings_product_cluster.pt\")\n",
    "product_emb = concat_emb #our final product embeddings are the concat category + cluster embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(product_emb, \"product_embeddings.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hetero Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = HeteroData()\n",
    "#data = torch.load(\"product_data_PYG.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData()\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_product_indices_by_user(df, product_mapping):\n",
    "    def map_product_ids(product_id_list):\n",
    "        return [product_mapping.get(product_id, 0) for product_id in product_id_list]  # 0 as the default for unknown IDs\n",
    "\n",
    "    user_product_indices = df.groupby(['user_id'])['product_id'].apply(map_product_ids)\n",
    "    return user_product_indices\n",
    "\n",
    "user_x_prod = get_product_indices_by_user(reviews_df, product_mapping)\n",
    "print(user_x_prod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5844\n",
      "torch.Size([941, 394])\n"
     ]
    }
   ],
   "source": [
    "print(reviews_df['user_id'].nunique())\n",
    "print(product_emb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_user_features(reviews_df, product_emb, model_name = None):\n",
    "    #Average past product embeddings\n",
    "    # add both user ID (user name?) and user embeddings (from user data) to the user node features\n",
    "\n",
    "    user_feat = []\n",
    "    for user_id in reviews_df['user_id'].unique():\n",
    "        user_df = reviews_df.loc[reviews_df['user_id'] == user_id]\n",
    "\n",
    "        positive_reviews = \" \".join(user_df[user_df['rating'] >= 3]['review_content'])\n",
    "        user_feat.append(f\"{user_df['username'].iloc[0]} {positive_reviews}\" if positive_reviews else \" \")\n",
    "\n",
    "        # past_product_indices =  user_x_prod.loc[(rev_user_mapping.get(user_id))]\n",
    "        # if len(past_product_indices) > 0: \n",
    "        #     user_feat.append(torch.mean(product_emb[past_product_indices], dim=0)) \n",
    "        # else:\n",
    "        #     user_feat.append(torch.zeros_like(concat_emb[0])) # Default if no past interactions\n",
    "    \n",
    "    model = SentenceTransformer(model_name, device=device)\n",
    "    user_embeddings = model.encode(user_feat, show_progress_bar=True,\n",
    "                              convert_to_tensor=True, device=device)\n",
    "    \n",
    "    print(\"Shape of user_embeddings before returning:\", user_embeddings.shape)\n",
    "    \n",
    "    return user_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  user={ x=[5844, 384] },\n",
      "  products={ x=[941, 394] },\n",
      "  (user, ratings, products)={\n",
      "    edge_index=[2, 6100],\n",
      "    edge_label=[6100],\n",
      "  }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbf24d5ee2e44f259de0b04068dc75c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/183 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of user_embeddings before returning: torch.Size([5844, 384])\n"
     ]
    }
   ],
   "source": [
    "#TODO plot graph \n",
    "data['user'].x = compute_user_features(reviews_df, product_emb, model_name='all-MiniLM-L6-v2').to(device)\n",
    "data['products'].x = product_emb\n",
    "data['user', 'ratings', 'products'].edge_index = edge_index\n",
    "data['user', 'ratings', 'products'].edge_label = edge_label\n",
    "#torch.save(data, 'product_data_PYG.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  user={ x=[5844, 384] },\n",
      "  products={ x=[941, 394] },\n",
      "  (user, ratings, products)={\n",
      "    edge_index=[2, 6100],\n",
      "    edge_label=[6100],\n",
      "  }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_user_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreviews_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproduct_emb\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mall-MiniLM-L6-v2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mnum_nodes\n",
      "Cell \u001b[1;32mIn[50], line 7\u001b[0m, in \u001b[0;36mcompute_user_features\u001b[1;34m(reviews_df, product_emb, model_name)\u001b[0m\n\u001b[0;32m      5\u001b[0m user_feat \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m user_id \u001b[38;5;129;01min\u001b[39;00m reviews_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique():\n\u001b[1;32m----> 7\u001b[0m     user_df \u001b[38;5;241m=\u001b[39m \u001b[43mreviews_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mreviews_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muser_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43muser_id\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      9\u001b[0m     positive_reviews \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(user_df[user_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrating\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreview_content\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     10\u001b[0m     user_feat\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00muser_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124musername\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpositive_reviews\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m positive_reviews \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\aj\\Code\\ArangoDB_project\\.venv\\Lib\\site-packages\\pandas\\core\\indexing.py:1191\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1189\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m   1190\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_deprecated_callable_usage(key, maybe_callable)\n\u001b[1;32m-> 1191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\aj\\Code\\ArangoDB_project\\.venv\\Lib\\site-packages\\pandas\\core\\indexing.py:1413\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1411\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_slice_axis(key, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[0;32m   1412\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_bool_indexer(key):\n\u001b[1;32m-> 1413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getbool_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1414\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like_indexer(key):\n\u001b[0;32m   1415\u001b[0m     \u001b[38;5;66;03m# an iterable multi-selection\u001b[39;00m\n\u001b[0;32m   1416\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(labels, MultiIndex)):\n",
      "File \u001b[1;32mc:\\Users\\aj\\Code\\ArangoDB_project\\.venv\\Lib\\site-packages\\pandas\\core\\indexing.py:1210\u001b[0m, in \u001b[0;36m_LocationIndexer._getbool_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1208\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis)\n\u001b[0;32m   1209\u001b[0m key \u001b[38;5;241m=\u001b[39m check_bool_indexer(labels, key)\n\u001b[1;32m-> 1210\u001b[0m inds \u001b[38;5;241m=\u001b[39m \u001b[43mkey\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnonzero\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_take_with_is_copy(inds, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data['user'].x = compute_user_features(reviews_df, product_emb,model_name='all-MiniLM-L6-v2').to(device)\n",
    "del data['user'].num_nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a reverse ('product', 'rev_ratings', 'user') relation for message passing.\n",
    "data = ToUndirected()(data)\n",
    "del data['products', 'rev_ratings', 'user'].edge_label  # Remove \"reverse\" label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  user={ x=[5844, 384] },\n",
      "  products={ x=[941, 394] },\n",
      "  (user, ratings, products)={\n",
      "    edge_index=[2, 6100],\n",
      "    edge_label=[6100],\n",
      "  },\n",
      "  (products, rev_ratings, user)={ edge_index=[2, 6100] }\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['user', 'products'],\n",
       " [('user', 'ratings', 'products'), ('products', 'rev_ratings', 'user')])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.to(device)\n",
    "print(data)\n",
    "data.metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a link-level split into training, validation, and test edges.\n",
    "train_data, val_data, test_data = T.RandomLinkSplit(\n",
    "    num_val=0.1,\n",
    "    num_test=0.1,\n",
    "    neg_sampling_ratio=0.0,\n",
    "    edge_types=[('user', 'ratings', 'products')],\n",
    "    rev_edge_types=[('products', 'rev_ratings', 'user')],\n",
    ")(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: HeteroData(\n",
      "  user={ x=[5844, 384] },\n",
      "  products={ x=[941, 394] },\n",
      "  (user, ratings, products)={\n",
      "    edge_index=[2, 4880],\n",
      "    edge_label=[4880],\n",
      "    edge_label_index=[2, 4880],\n",
      "  },\n",
      "  (products, rev_ratings, user)={ edge_index=[2, 4880] }\n",
      ")\n",
      "Val data: HeteroData(\n",
      "  user={ x=[5844, 384] },\n",
      "  products={ x=[941, 394] },\n",
      "  (user, ratings, products)={\n",
      "    edge_index=[2, 4880],\n",
      "    edge_label=[610],\n",
      "    edge_label_index=[2, 610],\n",
      "  },\n",
      "  (products, rev_ratings, user)={ edge_index=[2, 4880] }\n",
      ")\n",
      "Test data HeteroData(\n",
      "  user={ x=[5844, 384] },\n",
      "  products={ x=[941, 394] },\n",
      "  (user, ratings, products)={\n",
      "    edge_index=[2, 5490],\n",
      "    edge_label=[610],\n",
      "    edge_label_index=[2, 610],\n",
      "  },\n",
      "  (products, rev_ratings, user)={ edge_index=[2, 5490] }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print('Train data:', train_data)\n",
    "print('Val data:', val_data)\n",
    "print('Test data', test_data)\n",
    "torch.save(train_data, 'train_data.pt')\n",
    "torch.save(val_data, 'val_data.pt')\n",
    "torch.save(test_data, 'test_data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
       "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Slicing edge label to get the corresponding split (hence this gives train split)\n",
    "train_data['user', 'products'].edge_label_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user': tensor([[-3.9595e-02, -1.8005e-02, -1.6868e-02,  ...,  9.5934e-05,\n",
       "          -1.0221e-01,  6.9101e-02],\n",
       "         [-6.0112e-02,  4.8578e-02,  3.2484e-02,  ..., -3.2740e-02,\n",
       "          -4.7089e-02,  3.4276e-03],\n",
       "         [-9.0954e-03,  8.7616e-02,  2.7719e-02,  ...,  2.1840e-02,\n",
       "          -7.2182e-02,  5.8295e-02],\n",
       "         ...,\n",
       "         [-2.4396e-02, -4.0922e-02,  2.6919e-03,  ..., -6.7094e-03,\n",
       "           9.1775e-03, -1.8611e-02],\n",
       "         [-1.1884e-01,  4.8299e-02, -2.5480e-03,  ...,  1.2641e-01,\n",
       "           4.6549e-02, -1.5717e-02],\n",
       "         [ 1.5501e-02, -1.1461e-02, -4.3353e-04,  ..., -2.2426e-03,\n",
       "          -3.6879e-02,  2.7369e-02]], device='cuda:0'),\n",
       " 'products': tensor([[-1.7683e-02,  1.1559e-02,  3.8091e-02,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [-7.5590e-02,  6.2818e-02, -9.5776e-04,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  1.0000e+00],\n",
       "         [-4.7318e-03,  2.1906e-02,  6.5977e-02,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         ...,\n",
       "         [-7.7193e-03, -1.0832e-02,  3.2256e-02,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [-2.2587e-02,  2.9910e-02,  1.9334e-02,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [-4.6875e-02,  2.9643e-02, -5.1384e-03,  ...,  1.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00]], device='cuda:0')}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.x_dict\n",
    "#print((train_data.edge_index_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5844, 384]), torch.Size([941, 394]))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.x_dict['user'].shape, data.x_dict['products'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_global_store': {},\n",
       " 'user': {'x': tensor([[-3.9595e-02, -1.8005e-02, -1.6868e-02,  ...,  9.5934e-05,\n",
       "           -1.0221e-01,  6.9101e-02],\n",
       "          [-6.0112e-02,  4.8578e-02,  3.2484e-02,  ..., -3.2740e-02,\n",
       "           -4.7089e-02,  3.4276e-03],\n",
       "          [-9.0954e-03,  8.7616e-02,  2.7719e-02,  ...,  2.1840e-02,\n",
       "           -7.2182e-02,  5.8295e-02],\n",
       "          ...,\n",
       "          [-2.4396e-02, -4.0922e-02,  2.6919e-03,  ..., -6.7094e-03,\n",
       "            9.1775e-03, -1.8611e-02],\n",
       "          [-1.1884e-01,  4.8299e-02, -2.5480e-03,  ...,  1.2641e-01,\n",
       "            4.6549e-02, -1.5717e-02],\n",
       "          [ 1.5501e-02, -1.1461e-02, -4.3353e-04,  ..., -2.2426e-03,\n",
       "           -3.6879e-02,  2.7369e-02]], device='cuda:0')},\n",
       " 'products': {'x': tensor([[-1.7683e-02,  1.1559e-02,  3.8091e-02,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [-7.5590e-02,  6.2818e-02, -9.5776e-04,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  1.0000e+00],\n",
       "          [-4.7318e-03,  2.1906e-02,  6.5977e-02,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [-7.7193e-03, -1.0832e-02,  3.2256e-02,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [-2.2587e-02,  2.9910e-02,  1.9334e-02,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [-4.6875e-02,  2.9643e-02, -5.1384e-03,  ...,  1.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00]], device='cuda:0')},\n",
       " ('user',\n",
       "  'ratings',\n",
       "  'products'): {'edge_index': tensor([[   0,    1,    2,  ..., 5841, 5842, 5843],\n",
       "          [   0,    0,    1,  ...,  938,  939,  940]], device='cuda:0'), 'edge_label': tensor([5, 4, 5,  ..., 5, 1, 5], device='cuda:0')},\n",
       " ('products',\n",
       "  'rev_ratings',\n",
       "  'user'): {'edge_index': tensor([[   0,    0,    1,  ...,  938,  939,  940],\n",
       "          [   0,    1,    2,  ..., 5841, 5842, 5843]], device='cuda:0')}}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('user',\n",
       "  'ratings',\n",
       "  'products'): tensor([[   0,    1,    2,  ..., 5841, 5842, 5843],\n",
       "         [   0,    0,    1,  ...,  938,  939,  940]], device='cuda:0'),\n",
       " ('products',\n",
       "  'rev_ratings',\n",
       "  'user'): tensor([[   0,    0,    1,  ...,  938,  939,  940],\n",
       "         [   0,    1,    2,  ..., 5841, 5842, 5843]], device='cuda:0')}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.edge_index_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('user',\n",
       "  'ratings',\n",
       "  'products'): tensor([5, 4, 5,  ..., 5, 1, 5], device='cuda:0')}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.edge_label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Different types of nodes in graph: ['user', 'products']\n",
      "Different types of edges in graph: [('user', 'ratings', 'products'), ('products', 'rev_ratings', 'user')]\n"
     ]
    }
   ],
   "source": [
    "node_types, edge_types = data.metadata()\n",
    "print('Different types of nodes in graph:',node_types)\n",
    "print('Different types of edges in graph:',edge_types)\n",
    "torch.save(data, 'product_data_PYG.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have an unbalanced dataset with many labels for rating 3 and 4, and very\n",
    "# few for 0 and 1. Therefore we use a weighted MSE loss.\n",
    "\n",
    "#May want to play with varieties\n",
    "weight = torch.bincount(train_data['user', 'products'].edge_label)\n",
    "weight = weight.max() / weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_mse_loss(pred, target, weight=None):\n",
    "    weight = 1. if weight is None else weight[target].to(pred.dtype)\n",
    "    return (weight * (pred - target.to(pred.dtype)).pow(2)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "val_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  user={ x=[5844, 384] },\n",
      "  products={ x=[941, 394] },\n",
      "  (user, ratings, products)={\n",
      "    edge_index=[2, 6100],\n",
      "    edge_label=[6100],\n",
      "  },\n",
      "  (products, rev_ratings, user)={ edge_index=[2, 6100] }\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['user', 'products'],\n",
       " [('user', 'ratings', 'products'), ('products', 'rev_ratings', 'user')])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.to(device)\n",
    "print(data)\n",
    "data.metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import SAGEConv, to_hetero, Linear\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "class GNNEncoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv((-1, -1), hidden_channels)\n",
    "        self.conv2 = SAGEConv((-1, -1), out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "class EdgeDecoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.lin1 = Linear(2 * hidden_channels, hidden_channels)\n",
    "        self.lin2 = Linear(hidden_channels, 1)\n",
    "\n",
    "    def forward(self, z_dict, edge_label_index):\n",
    "        row, col = edge_label_index\n",
    "        z = torch.cat([z_dict['user'][row], z_dict['products'][col]], dim=-1)\n",
    "        z = self.lin1(z).relu()\n",
    "        z = self.lin2(z)\n",
    "        return z.view(-1)\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.encoder = GNNEncoder(hidden_channels, hidden_channels)\n",
    "        self.encoder = to_hetero(self.encoder, data.metadata(), aggr='sum')\n",
    "        self.decoder = EdgeDecoder(hidden_channels)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict, edge_label_index):\n",
    "        z_dict = self.encoder(x_dict, edge_index_dict)\n",
    "        return self.decoder(z_dict, edge_label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(hidden_channels=32).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "train_losses = []\n",
    "val_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    print(train_data.edge_index_dict['user', 'ratings', 'products'])\n",
    "    pred = model(train_data.x_dict, train_data.edge_index_dict,\n",
    "                 train_data['user', 'products'].edge_label_index)\n",
    "    target = train_data['user', 'products'].edge_label\n",
    "    loss = weighted_mse_loss(pred, target, weight)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    #store training loss for graph\n",
    "    train_losses.append(float(loss))\n",
    "\n",
    "    return float(loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(data):\n",
    "    model.eval()\n",
    "    pred = model(data.x_dict, data.edge_index_dict,\n",
    "                 data['user', 'products'].edge_label_index)\n",
    "    pred = pred.clamp(min=0, max=5)\n",
    "    target = data['user', 'products'].edge_label.float()\n",
    "    rmse = F.mse_loss(pred, target).sqrt()\n",
    "\n",
    "    #store validation loss for graph\n",
    "    val_losses.append(float(rmse))\n",
    "\n",
    "    return float(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  user={ x=[5844, 384] },\n",
      "  products={ x=[941, 394] },\n",
      "  (user, ratings, products)={\n",
      "    edge_index=[2, 6100],\n",
      "    edge_label=[6100],\n",
      "  },\n",
      "  (products, rev_ratings, user)={ edge_index=[2, 6100] }\n",
      ")\n",
      "<class 'dict'>\n",
      "(['user', 'products'], [('user', 'ratings', 'products'), ('products', 'rev_ratings', 'user')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aj\\AppData\\Local\\Temp\\ipykernel_21216\\3619719553.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_data['user', 'products'].edge_index = torch.tensor(train_data['user', 'products'].edge_index)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['user', 'products'],\n",
       " [('user', 'ratings', 'products'), ('products', 'rev_ratings', 'user')])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.to(device)\n",
    "print(data)\n",
    "print(type(train_data.edge_index_dict))\n",
    "#data.metadata()\n",
    "print(train_data.metadata())\n",
    "train_data['user', 'products'].edge_index = torch.tensor(train_data['user', 'products'].edge_index)\n",
    "train_data.metadata()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 001, Loss: 32.4488, Train: 4.0306, Val: 4.0284, Test: 4.0755\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 002, Loss: 28.6678, Train: 3.6503, Val: 3.7456, Test: 3.7925\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 003, Loss: 22.3690, Train: 2.8689, Val: 3.1954, Test: 3.2415\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 004, Loss: 12.5408, Train: 1.5542, Val: 2.2424, Test: 2.2852\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 005, Loss: 7.3674, Train: 1.4221, Val: 1.7044, Test: 1.7468\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 006, Loss: 14.3533, Train: 1.3574, Val: 1.9926, Test: 2.0356\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 007, Loss: 7.5178, Train: 1.8168, Val: 2.4426, Test: 2.4840\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 008, Loss: 5.7327, Train: 2.1846, Val: 2.7445, Test: 2.7841\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 009, Loss: 7.0361, Train: 2.3104, Val: 2.8530, Test: 2.8909\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 010, Loss: 7.7616, Train: 2.2261, Val: 2.7997, Test: 2.8359\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 011, Loss: 7.1531, Train: 1.9678, Val: 2.6303, Test: 2.6646\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 012, Loss: 5.6075, Train: 1.5788, Val: 2.3651, Test: 2.3981\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 013, Loss: 4.0588, Train: 1.1778, Val: 2.0510, Test: 2.0850\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 014, Loss: 3.6852, Train: 0.9775, Val: 1.7956, Test: 1.8331\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 015, Loss: 4.6020, Train: 0.9347, Val: 1.7127, Test: 1.7508\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 016, Loss: 4.7889, Train: 0.9369, Val: 1.7956, Test: 1.8303\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 017, Loss: 3.7098, Train: 1.0700, Val: 1.9654, Test: 1.9950\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 018, Loss: 2.8329, Train: 1.2833, Val: 2.1325, Test: 2.1590\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 019, Loss: 2.7788, Train: 1.4430, Val: 2.2378, Test: 2.2627\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 020, Loss: 3.0819, Train: 1.4882, Val: 2.2596, Test: 2.2839\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 021, Loss: 3.1863, Train: 1.4119, Val: 2.1977, Test: 2.2216\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 022, Loss: 2.9134, Train: 1.2356, Val: 2.0635, Test: 2.0879\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 023, Loss: 2.4384, Train: 1.0140, Val: 1.8828, Test: 1.9095\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 024, Loss: 2.1331, Train: 0.8394, Val: 1.7030, Test: 1.7340\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 025, Loss: 2.2507, Train: 0.7651, Val: 1.5856, Test: 1.6197\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 026, Loss: 2.5439, Train: 0.7565, Val: 1.5708, Test: 1.6049\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 027, Loss: 2.5066, Train: 0.8048, Val: 1.6495, Test: 1.6809\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 028, Loss: 2.1704, Train: 0.9249, Val: 1.7748, Test: 1.8019\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 029, Loss: 1.9699, Train: 1.0682, Val: 1.8909, Test: 1.9151\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 030, Loss: 2.0491, Train: 1.1617, Val: 1.9582, Test: 1.9811\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 031, Loss: 2.2010, Train: 1.1685, Val: 1.9602, Test: 1.9831\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 032, Loss: 2.2112, Train: 1.0898, Val: 1.8993, Test: 1.9230\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 033, Loss: 2.0616, Train: 0.9572, Val: 1.7930, Test: 1.8187\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 034, Loss: 1.9140, Train: 0.8316, Val: 1.6777, Test: 1.7068\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 035, Loss: 1.9483, Train: 0.7721, Val: 1.6088, Test: 1.6409\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 036, Loss: 2.0719, Train: 0.7788, Val: 1.6185, Test: 1.6503\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 037, Loss: 2.0271, Train: 0.8409, Val: 1.6885, Test: 1.7175\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 038, Loss: 1.8943, Train: 0.9369, Val: 1.7765, Test: 1.8028\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 039, Loss: 1.8629, Train: 1.0181, Val: 1.8434, Test: 1.8678\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 040, Loss: 1.9213, Train: 1.0464, Val: 1.8667, Test: 1.8906\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 041, Loss: 1.9498, Train: 1.0138, Val: 1.8432, Test: 1.8676\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 042, Loss: 1.8974, Train: 0.9387, Val: 1.7847, Test: 1.8107\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 043, Loss: 1.8207, Train: 0.8564, Val: 1.7149, Test: 1.7434\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 044, Loss: 1.8019, Train: 0.8031, Val: 1.6645, Test: 1.6950\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 045, Loss: 1.8372, Train: 0.7925, Val: 1.6563, Test: 1.6872\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 046, Loss: 1.8396, Train: 0.8225, Val: 1.6916, Test: 1.7210\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 047, Loss: 1.7858, Train: 0.8812, Val: 1.7503, Test: 1.7773\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 048, Loss: 1.7459, Train: 0.9413, Val: 1.8048, Test: 1.8298\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 049, Loss: 1.7542, Train: 0.9729, Val: 1.8337, Test: 1.8577\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 050, Loss: 1.7699, Train: 0.9625, Val: 1.8289, Test: 1.8529\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 051, Loss: 1.7526, Train: 0.9183, Val: 1.7964, Test: 1.8210\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 052, Loss: 1.7171, Train: 0.8639, Val: 1.7530, Test: 1.7785\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 053, Loss: 1.7039, Train: 0.8251, Val: 1.7202, Test: 1.7464\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 054, Loss: 1.7162, Train: 0.8155, Val: 1.7142, Test: 1.7402\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 055, Loss: 1.7166, Train: 0.8351, Val: 1.7366, Test: 1.7613\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 056, Loss: 1.6933, Train: 0.8729, Val: 1.7744, Test: 1.7973\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 057, Loss: 1.6754, Train: 0.9092, Val: 1.8085, Test: 1.8299\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 058, Loss: 1.6777, Train: 0.9248, Val: 1.8243, Test: 1.8447\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 059, Loss: 1.6813, Train: 0.9123, Val: 1.8169, Test: 1.8370\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 060, Loss: 1.6696, Train: 0.8793, Val: 1.7918, Test: 1.8122\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 061, Loss: 1.6527, Train: 0.8431, Val: 1.7626, Test: 1.7835\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 062, Loss: 1.6475, Train: 0.8200, Val: 1.7446, Test: 1.7657\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 063, Loss: 1.6497, Train: 0.8177, Val: 1.7468, Test: 1.7674\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 064, Loss: 1.6435, Train: 0.8341, Val: 1.7666, Test: 1.7863\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 065, Loss: 1.6302, Train: 0.8590, Val: 1.7931, Test: 1.8116\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 066, Loss: 1.6225, Train: 0.8782, Val: 1.8134, Test: 1.8310\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 067, Loss: 1.6216, Train: 0.8812, Val: 1.8190, Test: 1.8361\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 068, Loss: 1.6176, Train: 0.8663, Val: 1.8089, Test: 1.8260\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 069, Loss: 1.6072, Train: 0.8417, Val: 1.7895, Test: 1.8069\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 070, Loss: 1.5982, Train: 0.8198, Val: 1.7713, Test: 1.7892\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 071, Loss: 1.5948, Train: 0.8110, Val: 1.7658, Test: 1.7837\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 072, Loss: 1.5911, Train: 0.8176, Val: 1.7761, Test: 1.7936\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 073, Loss: 1.5820, Train: 0.8342, Val: 1.7957, Test: 1.8125\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 074, Loss: 1.5735, Train: 0.8491, Val: 1.8127, Test: 1.8288\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 075, Loss: 1.5690, Train: 0.8531, Val: 1.8191, Test: 1.8350\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 076, Loss: 1.5642, Train: 0.8431, Val: 1.8128, Test: 1.8287\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 077, Loss: 1.5564, Train: 0.8255, Val: 1.7997, Test: 1.8162\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 078, Loss: 1.5496, Train: 0.8129, Val: 1.7926, Test: 1.8095\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 079, Loss: 1.5444, Train: 0.8126, Val: 1.7988, Test: 1.8156\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 080, Loss: 1.5368, Train: 0.8194, Val: 1.8115, Test: 1.8281\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 081, Loss: 1.5301, Train: 0.8245, Val: 1.8211, Test: 1.8375\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 082, Loss: 1.5247, Train: 0.8232, Val: 1.8234, Test: 1.8398\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 083, Loss: 1.5177, Train: 0.8150, Val: 1.8182, Test: 1.8350\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 084, Loss: 1.5097, Train: 0.8060, Val: 1.8123, Test: 1.8294\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 085, Loss: 1.5043, Train: 0.8055, Val: 1.8157, Test: 1.8328\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 086, Loss: 1.4975, Train: 0.8115, Val: 1.8261, Test: 1.8428\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 087, Loss: 1.4897, Train: 0.8144, Val: 1.8335, Test: 1.8499\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 088, Loss: 1.4836, Train: 0.8084, Val: 1.8326, Test: 1.8490\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 089, Loss: 1.4763, Train: 0.7970, Val: 1.8267, Test: 1.8435\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 090, Loss: 1.4687, Train: 0.7885, Val: 1.8239, Test: 1.8408\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 091, Loss: 1.4619, Train: 0.7893, Val: 1.8302, Test: 1.8469\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 092, Loss: 1.4543, Train: 0.7964, Val: 1.8424, Test: 1.8586\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 093, Loss: 1.4471, Train: 0.7986, Val: 1.8501, Test: 1.8660\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 094, Loss: 1.4401, Train: 0.7927, Val: 1.8508, Test: 1.8667\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 095, Loss: 1.4326, Train: 0.7876, Val: 1.8526, Test: 1.8683\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 096, Loss: 1.4249, Train: 0.7860, Val: 1.8576, Test: 1.8728\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 097, Loss: 1.4176, Train: 0.7814, Val: 1.8604, Test: 1.8753\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 098, Loss: 1.4105, Train: 0.7757, Val: 1.8628, Test: 1.8775\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 099, Loss: 1.4036, Train: 0.7774, Val: 1.8720, Test: 1.8858\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 100, Loss: 1.3955, Train: 0.7769, Val: 1.8798, Test: 1.8930\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 101, Loss: 1.3878, Train: 0.7734, Val: 1.8855, Test: 1.8981\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 102, Loss: 1.3808, Train: 0.7763, Val: 1.8955, Test: 1.9072\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 103, Loss: 1.3731, Train: 0.7715, Val: 1.8994, Test: 1.9108\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 104, Loss: 1.3650, Train: 0.7622, Val: 1.9004, Test: 1.9113\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 105, Loss: 1.3586, Train: 0.7738, Val: 1.9154, Test: 1.9250\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 106, Loss: 1.3523, Train: 0.7646, Val: 1.9157, Test: 1.9249\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 107, Loss: 1.3438, Train: 0.7467, Val: 1.9103, Test: 1.9190\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 108, Loss: 1.3389, Train: 0.7576, Val: 1.9256, Test: 1.9333\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 109, Loss: 1.3300, Train: 0.7667, Val: 1.9391, Test: 1.9462\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 110, Loss: 1.3257, Train: 0.7544, Val: 1.9382, Test: 1.9448\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 111, Loss: 1.3174, Train: 0.7457, Val: 1.9394, Test: 1.9455\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 112, Loss: 1.3134, Train: 0.7604, Val: 1.9558, Test: 1.9617\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 113, Loss: 1.3068, Train: 0.7561, Val: 1.9594, Test: 1.9651\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 114, Loss: 1.3008, Train: 0.7386, Val: 1.9544, Test: 1.9596\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 115, Loss: 1.2959, Train: 0.7418, Val: 1.9634, Test: 1.9684\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 116, Loss: 1.2892, Train: 0.7523, Val: 1.9769, Test: 1.9816\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 117, Loss: 1.2850, Train: 0.7450, Val: 1.9789, Test: 1.9835\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 118, Loss: 1.2791, Train: 0.7400, Val: 1.9813, Test: 1.9859\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 119, Loss: 1.2745, Train: 0.7487, Val: 1.9904, Test: 1.9954\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 120, Loss: 1.2703, Train: 0.7393, Val: 1.9888, Test: 1.9940\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 121, Loss: 1.2648, Train: 0.7291, Val: 1.9872, Test: 1.9923\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 122, Loss: 1.2614, Train: 0.7422, Val: 1.9994, Test: 2.0049\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 123, Loss: 1.2563, Train: 0.7376, Val: 2.0014, Test: 2.0067\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 124, Loss: 1.2519, Train: 0.7292, Val: 2.0002, Test: 2.0053\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 125, Loss: 1.2483, Train: 0.7363, Val: 2.0072, Test: 2.0126\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 126, Loss: 1.2428, Train: 0.7324, Val: 2.0080, Test: 2.0134\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 127, Loss: 1.2387, Train: 0.7282, Val: 2.0089, Test: 2.0142\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 128, Loss: 1.2344, Train: 0.7318, Val: 2.0142, Test: 2.0193\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 129, Loss: 1.2304, Train: 0.7271, Val: 2.0146, Test: 2.0197\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 130, Loss: 1.2266, Train: 0.7263, Val: 2.0165, Test: 2.0215\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 131, Loss: 1.2225, Train: 0.7265, Val: 2.0187, Test: 2.0236\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 132, Loss: 1.2186, Train: 0.7238, Val: 2.0192, Test: 2.0240\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 133, Loss: 1.2151, Train: 0.7263, Val: 2.0224, Test: 2.0273\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 134, Loss: 1.2113, Train: 0.7191, Val: 2.0206, Test: 2.0254\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 135, Loss: 1.2081, Train: 0.7291, Val: 2.0274, Test: 2.0322\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 136, Loss: 1.2061, Train: 0.7132, Val: 2.0202, Test: 2.0248\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 137, Loss: 1.2018, Train: 0.7150, Val: 2.0232, Test: 2.0278\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 138, Loss: 1.1978, Train: 0.7266, Val: 2.0317, Test: 2.0364\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 139, Loss: 1.1961, Train: 0.7133, Val: 2.0264, Test: 2.0311\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 140, Loss: 1.1912, Train: 0.7136, Val: 2.0286, Test: 2.0333\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 141, Loss: 1.1878, Train: 0.7231, Val: 2.0351, Test: 2.0397\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 142, Loss: 1.1864, Train: 0.7065, Val: 2.0274, Test: 2.0316\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 143, Loss: 1.1829, Train: 0.7145, Val: 2.0329, Test: 2.0371\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 144, Loss: 1.1785, Train: 0.7143, Val: 2.0342, Test: 2.0382\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 145, Loss: 1.1756, Train: 0.7045, Val: 2.0308, Test: 2.0343\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 146, Loss: 1.1744, Train: 0.7259, Val: 2.0434, Test: 2.0471\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 147, Loss: 1.1753, Train: 0.7059, Val: 2.0328, Test: 2.0362\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 148, Loss: 1.1674, Train: 0.6889, Val: 2.0238, Test: 2.0269\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 149, Loss: 1.1706, Train: 0.7258, Val: 2.0469, Test: 2.0501\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 150, Loss: 1.1686, Train: 0.7200, Val: 2.0445, Test: 2.0475\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 151, Loss: 1.1634, Train: 0.6857, Val: 2.0244, Test: 2.0274\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 152, Loss: 1.1635, Train: 0.7020, Val: 2.0370, Test: 2.0398\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 153, Loss: 1.1542, Train: 0.7227, Val: 2.0516, Test: 2.0542\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 154, Loss: 1.1560, Train: 0.7064, Val: 2.0432, Test: 2.0457\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 155, Loss: 1.1491, Train: 0.6887, Val: 2.0326, Test: 2.0350\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 156, Loss: 1.1509, Train: 0.7088, Val: 2.0459, Test: 2.0482\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 157, Loss: 1.1444, Train: 0.7140, Val: 2.0496, Test: 2.0518\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 158, Loss: 1.1443, Train: 0.6923, Val: 2.0374, Test: 2.0395\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 159, Loss: 1.1406, Train: 0.6940, Val: 2.0400, Test: 2.0420\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 160, Loss: 1.1372, Train: 0.7100, Val: 2.0516, Test: 2.0534\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 161, Loss: 1.1355, Train: 0.7021, Val: 2.0481, Test: 2.0498\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 162, Loss: 1.1318, Train: 0.6907, Val: 2.0412, Test: 2.0430\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 163, Loss: 1.1312, Train: 0.7047, Val: 2.0497, Test: 2.0514\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 164, Loss: 1.1281, Train: 0.7009, Val: 2.0474, Test: 2.0491\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 165, Loss: 1.1256, Train: 0.6862, Val: 2.0390, Test: 2.0407\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 166, Loss: 1.1243, Train: 0.6988, Val: 2.0484, Test: 2.0498\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 167, Loss: 1.1203, Train: 0.7044, Val: 2.0528, Test: 2.0541\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 168, Loss: 1.1191, Train: 0.6881, Val: 2.0434, Test: 2.0446\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 169, Loss: 1.1174, Train: 0.6955, Val: 2.0483, Test: 2.0493\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 170, Loss: 1.1132, Train: 0.7017, Val: 2.0522, Test: 2.0532\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 171, Loss: 1.1128, Train: 0.6868, Val: 2.0437, Test: 2.0446\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 172, Loss: 1.1093, Train: 0.6875, Val: 2.0458, Test: 2.0466\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 173, Loss: 1.1069, Train: 0.7024, Val: 2.0562, Test: 2.0571\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 174, Loss: 1.1064, Train: 0.6906, Val: 2.0495, Test: 2.0502\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 175, Loss: 1.1021, Train: 0.6838, Val: 2.0448, Test: 2.0456\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 176, Loss: 1.1009, Train: 0.6987, Val: 2.0539, Test: 2.0546\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 177, Loss: 1.1007, Train: 0.6879, Val: 2.0477, Test: 2.0482\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 178, Loss: 1.0961, Train: 0.6776, Val: 2.0425, Test: 2.0427\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 179, Loss: 1.0969, Train: 0.7027, Val: 2.0596, Test: 2.0597\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 180, Loss: 1.0948, Train: 0.6927, Val: 2.0537, Test: 2.0537\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 181, Loss: 1.0902, Train: 0.6726, Val: 2.0402, Test: 2.0400\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 182, Loss: 1.0916, Train: 0.6947, Val: 2.0548, Test: 2.0549\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 183, Loss: 1.0876, Train: 0.6941, Val: 2.0553, Test: 2.0554\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 184, Loss: 1.0851, Train: 0.6738, Val: 2.0436, Test: 2.0436\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 185, Loss: 1.0842, Train: 0.6885, Val: 2.0546, Test: 2.0548\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 186, Loss: 1.0797, Train: 0.6968, Val: 2.0600, Test: 2.0605\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 187, Loss: 1.0795, Train: 0.6765, Val: 2.0464, Test: 2.0470\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 188, Loss: 1.0756, Train: 0.6737, Val: 2.0448, Test: 2.0456\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 189, Loss: 1.0743, Train: 0.6964, Val: 2.0603, Test: 2.0611\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 190, Loss: 1.0745, Train: 0.6840, Val: 2.0531, Test: 2.0538\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 191, Loss: 1.0692, Train: 0.6658, Val: 2.0415, Test: 2.0419\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 192, Loss: 1.0732, Train: 0.6969, Val: 2.0625, Test: 2.0631\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 193, Loss: 1.0688, Train: 0.6887, Val: 2.0571, Test: 2.0577\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 194, Loss: 1.0649, Train: 0.6611, Val: 2.0387, Test: 2.0391\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 195, Loss: 1.0669, Train: 0.6823, Val: 2.0549, Test: 2.0554\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 196, Loss: 1.0595, Train: 0.6976, Val: 2.0655, Test: 2.0661\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 197, Loss: 1.0611, Train: 0.6698, Val: 2.0472, Test: 2.0476\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 198, Loss: 1.0572, Train: 0.6721, Val: 2.0481, Test: 2.0487\n",
      "tensor([[ 356, 2786, 2035,  ..., 5181, 4394, 2332],\n",
      "        [  83,  395,  295,  ...,  812,  659,  337]], device='cuda:0')\n",
      "Epoch: 199, Loss: 1.0538, Train: 0.6868, Val: 2.0581, Test: 2.0587\n"
     ]
    }
   ],
   "source": [
    "best_val_rmse = float('inf')\n",
    "for epoch in range(1,200):\n",
    "    # Convert edge_index to the appropriate format\n",
    "    # adding both \n",
    "    loss = train()\n",
    "    train_rmse = test(train_data)\n",
    "    val_rmse = test(val_data)\n",
    "    test_rmse = test(test_data)\n",
    "    if val_rmse < best_val_rmse:\n",
    "        best_val_rmse = val_rmse\n",
    "        torch.save(model.state_dict(), 'amazon_best_model.pt')\n",
    "\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Train: {train_rmse:.4f}, '\n",
    "          f'Val: {val_rmse:.4f}, Test: {test_rmse:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Graphing training loss vs validation loss vs epoch\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlim(0, 200)\n",
    "plt.ylim(0,30)\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##-> observation, making product embeddings fancier doesn't seem to have done much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_product_recommendations(model, data, user_id, total_products):\n",
    "    user_row = torch.tensor([user_id] * total_products).to(device)\n",
    "    #print(\"user row is\", user_row)\n",
    "    all_product_ids = torch.arange(total_products).to(device)\n",
    "    edge_label_index = torch.stack([user_row, all_product_ids], dim=0)\n",
    "\n",
    "    pred = model(data.x_dict, data.edge_index_dict, edge_label_index).to('cpu')\n",
    "    top_five_indices = pred.topk(5).indices\n",
    "\n",
    "    recommended_products = reviews_df[\"product_id\"].iloc[top_five_indices]\n",
    "    return recommended_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "739    B000F9Z1WI\n",
      "862    B000FFRY3G\n",
      "125    B0002TJAZK\n",
      "454    B000E7WM0K\n",
      "693    B000F7PW8S\n",
      "Name: product_id, dtype: object\n",
      "\n",
      "\n",
      "739    B000F9Z1WI\n",
      "862    B000FFRY3G\n",
      "125    B0002TJAZK\n",
      "454    B000E7WM0K\n",
      "693    B000F7PW8S\n",
      "Name: product_id, dtype: object\n"
     ]
    }
   ],
   "source": [
    "rec1 = get_product_recommendations(model, data, 0, len(products))\n",
    "rec2 = get_product_recommendations(model, data, 2, len(products))\n",
    "print(rec1)\n",
    "print(\"\\n\")\n",
    "print(rec2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 55.24it/s]\n"
     ]
    }
   ],
   "source": [
    "#TODO cosine similarity - op on embeddings\n",
    "#Look into arith. ops on embeddings in general\n",
    "total_users = len(users)\n",
    "total_prods = len(products)\n",
    "prod_recs = []\n",
    "for user_id in tqdm(range(0, 10)):\n",
    "    user_row = torch.tensor([user_id] * total_prods)\n",
    "    all_prod_ids = torch.arange(total_prods)\n",
    "    edge_label_index = torch.stack([user_row, all_prod_ids], dim=0)\n",
    "    pred = model(data.x_dict, data.edge_index_dict,\n",
    "             edge_label_index)\n",
    "    pred = pred.clamp(min=0, max=5)\n",
    "    # we will only select products for the user where the predicting rating is > 3.5 \n",
    "    #TODO understand why 3.5 is important value here; 4 gives empty arrays, 1 gives uniform arrays\n",
    "    #for example, pred>3.7 is empty arrays for all but user 5 out of 10 users\n",
    "    rec_prod_ids = (pred > 4.55).nonzero(as_tuple=True)\n",
    "    top_ten_recs = [rec_prods for rec_prods in rec_prod_ids[0].tolist()[:10]]\n",
    "    prod_recs.append({'user': user_id, 'rec_products': top_ten_recs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'user': 0, 'rec_products': [0, 1, 2, 4, 5, 6, 9, 10, 12, 14]}, {'user': 1, 'rec_products': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}, {'user': 2, 'rec_products': [0, 1, 2, 3, 4, 5, 6, 8, 9, 10]}, {'user': 3, 'rec_products': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}, {'user': 4, 'rec_products': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}, {'user': 5, 'rec_products': []}, {'user': 6, 'rec_products': []}, {'user': 7, 'rec_products': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}, {'user': 8, 'rec_products': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}, {'user': 9, 'rec_products': [125, 454, 693, 739, 862]}]\n"
     ]
    }
   ],
   "source": [
    "print(prod_recs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
